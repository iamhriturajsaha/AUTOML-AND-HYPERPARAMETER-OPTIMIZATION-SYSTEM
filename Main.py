# -*- coding: utf-8 -*-
"""Main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RTJAFRMQ7OEZERd27sxVFMtV0iVC0NH5
"""

# Project Name - AutoML and Hyperparameter Optimization System.

# Step 1 - Install Libraries

!pip install optuna lightgbm xgboost seaborn

# Step 2 - Import Libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb
import lightgbm as lgb
import optuna

# Step 3 - Upload Dataset

from google.colab import files
uploaded = files.upload()
import zipfile, io, os
if any(name.endswith('.zip') for name in uploaded.keys()):
    with zipfile.ZipFile(io.BytesIO(list(uploaded.values())[0]), 'r') as z:
        z.extractall()
        print("Extracted files:", z.namelist())
# Load CSV files
train_df = pd.read_csv("Dataset/Train.csv")
test_df = pd.read_csv("Dataset/Test.csv")
gender_df = pd.read_csv("Dataset/Gender Submission.csv")
print("Train shape:", train_df.shape)
print("Test shape:", test_df.shape)

# Step 4 - Data Preprocessing

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
def preprocess_data(train_df, test_df):
    train = train_df.copy()
    test = test_df.copy()
    # Fill missing values
    for df in [train, test]:
        df['Age'] = df['Age'].fillna(df['Age'].median())
        df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
        if "Fare" in df.columns:
            df['Fare'] = df['Fare'].fillna(df['Fare'].median())
        # Feature Engineering
        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
        df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
        # Use raw string for regex
        df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\.', expand=False)
        # Map similar titles into categories
        df['Title'] = df['Title'].replace(['Mlle','Ms'], 'Miss')
        df['Title'] = df['Title'].replace(['Mme'], 'Mrs')
        df['Title'] = df['Title'].replace(
            ['Don','Rev','Dr','Major','Lady','Sir','Col','Capt','Countess','Jonkheer','Dona'],
            'Rare'
        )
    # Drop unused columns
    drop_cols = ['PassengerId','Name','Ticket','Cabin']
    train = train.drop(columns=drop_cols, errors='ignore')
    test = test.drop(columns=drop_cols, errors='ignore')
    # Encode categorical features using combined data
    cat_cols = ['Sex','Embarked','Title']
    combined = pd.concat([train[cat_cols], test[cat_cols]], axis=0)
    encoders = {}
    for col in cat_cols:
        le = LabelEncoder()
        le.fit(combined[col])
        train[col] = le.transform(train[col])
        test[col] = le.transform(test[col])
        encoders[col] = le
    return train, test, encoders
# Apply preprocessing
train, test, encoders = preprocess_data(train_df, test_df)
X = train.drop("Survived", axis=1)
y = train["Survived"]
print("Processed features:", X.shape)
# Define features and target
X = train.drop("Survived", axis=1)
y = train["Survived"]
# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Shapes ->", X_train.shape, X_test.shape, y_train.shape, y_test.shape)
X.head(20)

# Step 5  - EDA & Visualizations

# Target distribution
plt.figure(figsize=(6,4))
sns.countplot(x=y, hue=y, palette="Set2", legend=False)
plt.title("Target Distribution (Survived)", fontsize=14)
plt.xlabel("Survived", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.xticks([0,1], ["Not Survived", "Survived"])
plt.show()
# Correlation Heatmap
plt.figure(figsize=(10,6))
sns.heatmap(train.corr(numeric_only=True), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Heatmap", fontsize=14)
plt.show()
# Correlation of features with target
corr_with_target = train.corr(numeric_only=True)["Survived"].sort_values(ascending=False)
plt.figure(figsize=(8,5))
sns.barplot(x=corr_with_target.values,
            y=corr_with_target.index,
            color="skyblue")
plt.title("Correlation of Features with Survival", fontsize=14)
plt.xlabel("Correlation", fontsize=12)
plt.show()
# Categorical comparisons
plt.figure(figsize=(6,4))
sns.barplot(x="Sex", y="Survived", data=train, hue="Sex", palette="Set1", legend=False)
plt.title("Survival Rate by Sex", fontsize=14)
plt.show()
plt.figure(figsize=(6,4))
sns.barplot(x="Pclass", y="Survived", data=train, hue="Pclass", palette="Set3", legend=False)
plt.title("Survival Rate by Passenger Class", fontsize=14)
plt.show()

# Step 6 - Baseline Models

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report
import xgboost as xgb
import lightgbm as lgb
# Train-Test Split
X = train.drop("Survived", axis=1)
y = train["Survived"]
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
# Define Baseline Models
baseline_models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "XGBoost": xgb.XGBClassifier(eval_metric="logloss", random_state=42),
    "LightGBM": lgb.LGBMClassifier(random_state=42)
}
print("===== Baseline Model Performance =====")
baseline_results = {}
for name, model in baseline_models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    score = model.score(X_test, y_test)
    baseline_results[name] = score
    print(f"\n{name} Performance:")
    print(classification_report(y_test, preds))
# Show Model Accuracies
print("\n===== Baseline Model Accuracy Summary =====")
for name, acc in baseline_results.items():
    print(f"{name}: {acc:.4f}")

# Step 7 - Hyperparameter Optimization

# Logistic Regression (Grid Search)
param_grid_lr = {
    "C": [0.01, 0.1, 1, 10],
    "penalty": ["l2"],
    "solver": ["lbfgs", "liblinear"]
}
grid_lr = GridSearchCV(
    LogisticRegression(max_iter=1000, random_state=42),
    param_grid_lr,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)
grid_lr.fit(X_train, y_train)
# Random Forest (Random Search)
param_dist_rf = {
    "n_estimators": [100, 200, 300, 400],
    "max_depth": [None, 5, 10, 15],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4]
}
rand_rf = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_dist_rf,
    n_iter=20,
    cv=5,
    scoring="accuracy",
    n_jobs=-1,
    random_state=42
)
rand_rf.fit(X_train, y_train)
# SVM (Grid Search)
param_grid_svm = {
    "C": [0.1, 1, 10],
    "kernel": ["linear", "rbf"],
    "gamma": ["scale", "auto"]
}
grid_svm = GridSearchCV(
    SVC(probability=True, random_state=42),
    param_grid_svm,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)
grid_svm.fit(X_train, y_train)
# XGBoost (Optuna)
def objective_xgb(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 100, 500),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "random_state": 42,
        "eval_metric": "logloss"  # keeps it clean, no warnings
    }
    model = xgb.XGBClassifier(**params)
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
    return scores.mean()
study_xgb = optuna.create_study(direction="maximize")
study_xgb.optimize(objective_xgb, n_trials=50)
# LightGBM (Optuna)
def objective_lgb(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 100, 500),
        "max_depth": trial.suggest_int("max_depth", -1, 10),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "num_leaves": trial.suggest_int("num_leaves", 20, 100),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "random_state": 42
    }
    model = lgb.LGBMClassifier(**params)
    scores = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
    return scores.mean()
study_lgb = optuna.create_study(direction="maximize")
study_lgb.optimize(objective_lgb, n_trials=50)

# Step 8 - Final Model Selection
final_results = {
    "Logistic Regression": grid_lr.best_score_,
    "Random Forest": rand_rf.best_score_,
    "SVM": grid_svm.best_score_,
    "XGBoost": study_xgb.best_value,
    "LightGBM": study_lgb.best_value
}
print("\n===== Final Comparison (CV Accuracy) =====")
for model_name, score in final_results.items():
    print(f"{model_name}: {score:.4f}")
best_model_name = max(final_results, key=final_results.get)
print(f"\nâœ… Best Model Selected: {best_model_name} "
      f"with Accuracy = {final_results[best_model_name]:.4f}")